{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "7WLI4AJGiLii"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- creating the datasets for training\n",
    "- instantiate some 2d/3d Unet\n",
    "- training loop\n"
   ],
   "metadata": {
    "id": "AM59PvlsuecR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import monai\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import os"
   ],
   "metadata": {
    "id": "ZZeVeIWqvKlP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = \"database\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Please update your data path to an existing folder.\")\n",
    "elif not set([\"training\", \"testing\"]).issubset(set(os.listdir(data_path))):\n",
    "    print(\"Please update your data path to the correct folder (should contain train, val and test folders).\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct folder :)\")"
   ],
   "metadata": {
    "id": "Bq0jE-_SxSVZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ACDCDataset(monai.data.Dataset):\n",
    "    def __init__(self, rootpath, mode, transform=None):\n",
    "        if mode not in [\"training\", \"testing\"]:\n",
    "            raise Exception(\"must be either training or testing for the dataset to be loaded\")\n",
    "\n",
    "        self.path = os.path.join(rootpath, mode)\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        returns dict{2dimg, 2dmask}\n",
    "        \"\"\"\n",
    "        for patient in next(os.walk(self.path))[1]:\n",
    "            patient_paths = glob.glob(os.path.join(self.path, patient, '*.gz'))\n",
    "\n",
    "            patient_paths.sort()\n",
    "            self.load_patient(patient_paths)\n",
    "\n",
    "    def load_patient(self, patient_paths):\n",
    "        for combi in [(1, 2), (3, 4)]:\n",
    "            image = sitk.ReadImage(patient_paths[combi[0]])\n",
    "            image_array = sitk.GetArrayFromImage(image)\n",
    "\n",
    "            mask = sitk.ReadImage(patient_paths[combi[1]])\n",
    "            mask_array = sitk.GetArrayFromImage(mask)\n",
    "\n",
    "            for i in range(image_array.shape[0]):\n",
    "                dictionary = {}\n",
    "                dictionary['img'] = image_array[i, :, :]\n",
    "                dictionary['mask'] = mask_array[i, :, :]\n",
    "\n",
    "                self.data.append(dictionary)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Make getitem return a dictionary with keys ['img', 'label'] for the image and label respectively\n",
    "        item = self.data[index]\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "    def get_total_meansd(self):\n",
    "        norm = []\n",
    "        for x in self.data:\n",
    "          norm.append(x[\"img\"])\n",
    "\n",
    "        norm = np.array(norm)\n",
    "        return np.mean(norm), np.std(norm)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "id": "Fvk_u61p5OUo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transforms = monai.transforms.Compose([\n",
    "    monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "    monai.transforms.NormalizeIntensityd(keys='img', subtrahend=67.27, divisor=84.66),\n",
    "    monai.transforms.Resized(keys=['img', 'mask'], spatial_size=(200, 200))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = ACDCDataset(data_path, \"training\", transforms)\n",
    "test_dataset = ACDCDataset(data_path, \"testing\", transforms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = monai.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = monai.data.DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ],
   "metadata": {
    "id": "p-bYhaksADBY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_sample(sample, title=None):\n",
    "    # Visualize the x-ray and overlay the mask, using the dictionary as input\n",
    "    image = np.squeeze(sample['img'])\n",
    "    mask = np.squeeze(sample['mask'])\n",
    "    plt.figure(figsize=[10,7])\n",
    "    plt.imshow(image, 'gray')\n",
    "    overlay_mask = np.ma.masked_where(mask == 0, mask == 1)\n",
    "    plt.imshow(overlay_mask, 'Greens', alpha = 0.7, clim=[0,1], interpolation='nearest')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "kuIjNGt80KlN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_sample(train_dataset[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'The used device is {device}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import monai\n",
    "import torch\n",
    "\n",
    "loss_function =  monai.losses.DiceLoss(sigmoid=True, batch=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}\")\n",
    "    epoch_losses = {'train': [], 'val': []}\n",
    "    batch_data = {'train': [], 'val': []}\n",
    "    outputs = {'train': [], 'val': []}\n",
    "\n",
    "    for mode in ['train', 'val']:\n",
    "    # for mode in ['train']:\n",
    "        print(f\"Current mode: {mode}\")\n",
    "        for i, batch in enumerate(tqdm(dataloaders[mode])):\n",
    "            # batch_data[mode].extend(batch['img'])\n",
    "            # batch_data[mode].extend(batch['mask'])\n",
    "            x_batch = batch['img'].to(device)\n",
    "            y_batch = batch['mask'].to(device)\n",
    "\n",
    "            output = model(x_batch)\n",
    "\n",
    "            loss = loss_function(output, y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # outputs[mode].extend(output.cpu().numpy)\n",
    "            epoch_losses[mode].append(loss.item())\n",
    "        print(f\"Mean loss in {mode} mode: {np.mean(epoch_losses[mode])}\")\n",
    "\n",
    "    # log_to_wandb(epoch, epoch_loss['train'], epoch_loss['val'], batch_data['train'], outputs['train'])\n",
    "\n",
    "\n",
    "# Store the network parameters\n",
    "torch.save(model.state_dict(), r'trainedUNet.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch = iter(test_loader).next()\n",
    "\n",
    "outputs = model(batch['img'].to(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_sample({'img': batch['img'][0, 0, :, :], 'mask': outputs.detach().cpu().numpy()[0, 0, :, :]>0})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.imshow(batch['img'][0, 0, :, :], cmap='gray')\n",
    "plt.imshow(outputs.detach().cpu().numpy()[0, 0, :, :], alpha=.5)\n",
    "plt.imshow(batch['mask'][0, 0, :, :] > 0, alpha=.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outputs.detach().cpu().numpy()[0] > 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outputs.detach().cpu().numpy()[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
